# ğŸ§¬ Rick and Morty ETL Project

This project extracts character data from the [Rick and Morty API](https://rickandmortyapi.com/), loads it into a **PostgreSQL staging table**, and applies **Slowly Changing Dimension (SCD) Type 2** logic to maintain historical records in a dimension table.

It is designed using modular Python scripts for easy maintenance and scalability.

---

## ğŸ“ Project Structure

```
rick_etl_project/
â”œâ”€â”€ .env                         # Environment variables for PostgreSQL
â”œâ”€â”€ extract_char.py              # Extract: Fetches character data from API
â”œâ”€â”€ db_utils.py                  # Utility: Connects to PostgreSQL via SQLAlchemy
â”œâ”€â”€ load/
â”‚   â””â”€â”€ load_to_staging.py       # Load: Pushes CSV to staging table
â”œâ”€â”€ transform/
â”‚   â””â”€â”€ merge_dim_character.sql  # Transform: SQL logic for SCD Type 2 merge
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ddl_staging.sql          # SQL: Create staging table
â”‚   â””â”€â”€ ddl_dim.sql              # SQL: Create dimension table
â”œâ”€â”€ etl/
â”‚   â””â”€â”€ run_pipeline.py          # Orchestration script for the ETL process
â””â”€â”€ data/
    â””â”€â”€ charlist.csv             # Extracted character data as CSV
```

---

## âš™ï¸ Setup Instructions (macOS)

### 1. Clone the repository

```bash
git clone https://github.com/your-username/rick-etl-project.git
cd rick-etl-project
```

### 2. Create and activate a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Create a `.env` file

Create a `.env` file at the project root:

```env
DB_USER=your_user
DB_PASSWORD=your_password
DB_HOST=localhost
DB_PORT=5432
DB_NAME=sandbox
```

### 5. Create PostgreSQL tables

Run these in your database:

```sql
-- Create staging and dimension schemas/tables
\i models/ddl_staging.sql
\i models/ddl_dim.sql
```

### 6. Run the pipeline

```bash
python etl/run_pipeline.py
```

---

## ğŸ’¡ What the Pipeline Does

1. **Extract**: API â†’ CSV (`data/charlist.csv`)
2. **Load**: CSV â†’ `staging.rick_and_morty_characters`
3. **Transform**: Applies SCD2 logic â†’ `dim.dim_character`

---

## ğŸ›  Technologies Used

- Python (pandas, requests, SQLAlchemy)
- PostgreSQL 15+
- SQL DDL and DML (with `MERGE`)
- `.env` configuration via `python-dotenv`

---

## ğŸ“Š Sample Output (dim.dim_character)

| character_key | character_name  | episode_count | is_current | effective_date | end_date  |
|---------------|------------------|---------------|------------|----------------|-----------|
| 1             | Rick Sanchez     | 51            | true       | 2025-05-10     | NULL      |
| 2             | Morty Smith      | 50            | false      | 2024-12-01     | 2025-05-01 |

---

## ğŸ”’ Notes

- Requires PostgreSQL version 15 or higher for native `MERGE` support.
- `MERGE` script handles SCD2 logic with `is_current`, `end_date`, and `effective_date`.

---

## âœ… Future Enhancements

- Airflow integration for scheduling
- Logging and monitoring
- API schema validation
- Unit tests and coverage reports

---

## ğŸ™Œ Acknowledgements

- [Rick and Morty API](https://rickandmortyapi.com/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)